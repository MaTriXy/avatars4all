{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eyaler/avatars4all/blob/master/facevidcrop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#FaceVidCrop\n",
        "\n",
        "### Notebook by [Eyal Gruss](https://eyalgruss.com), [@eyaler](twitter.com/eyaler)\n",
        "\n",
        "Crop a video to center on a face + optionally upscale/restore with [GFPGAN](https://github.com/TencentARC/GFPGAN)\n",
        "\n",
        "More notebooks: [github.com/eyaler/avatars4all](https://github.com/eyaler/avatars4all)\n",
        "\n",
        "Shortcut here: [tfi.la/face](https://tfi.la/face)\n",
        "\n",
        "Something not working? Open an [issue](https://github.com/eyaler/avatars4all/issues)\n",
        "\n",
        "If you find my work useful please consider supporting me via [GitHub Sponsors](https://github.com/sponsors/eyaler) or [PayPal](https://www.paypal.com/donate/?hosted_button_id=LNJ6F3FR79ARE)"
      ],
      "metadata": {
        "id": "fIHL9q7CJ4tR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Setup\n",
        "\n",
        "import locale\n",
        "locale.getpreferredencoding = lambda: 'UTF-8'\n",
        "\n",
        "!pip install git+https://github.com/ytdl-org/youtube-dl\n",
        "!pip install git+https://github.com/1adrianb/face-alignment\n",
        "\n",
        "%cd /content\n",
        "!git clone --depth=1 https://github.com/TencentARC/GFPGAN\n",
        "%cd /content/GFPGAN\n",
        "!pip install basicsr\n",
        "!pip install facexlib\n",
        "!pip install -r requirements.txt\n",
        "!python setup.py develop\n",
        "!pip install realesrgan\n",
        "%cd /content"
      ],
      "metadata": {
        "cellView": "form",
        "id": "NrVPvyVku1BJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Optionally mount Google Drive (MARK CHECKBOX) { run: \"auto\" }\n",
        "mount_google_drive = False #@param {type:\"boolean\"}\n",
        "if mount_google_drive:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')\n",
        "  print('path is /content/drive/MyDrive')"
      ],
      "metadata": {
        "cellView": "form",
        "id": "ods_VYgxFFaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANINpF9JKuk8",
        "cellView": "form"
      },
      "source": [
        "#@title Crop video to face\n",
        "\n",
        "video_url = 'https://www.youtube.com/watch?v=vfIHsurwTMo' #@param {type: 'string'}\n",
        "#@markdown (leave empty to upload file - A BUTTON WILL APPEAR BELOW, or link to youtube / vimeo / video url / path to video on mounted drive [/content/drive/MyDrive/...] / path to video on colab)\n",
        "i_just_uploaded_a_file_and_i_want_to_reuse_that_instead_of_uploading_a_new_one = False  #@param {type: 'boolean'}\n",
        "face_order = 'left-to-right then top-to-bottom' #@param ['left-to-right then top-to-bottom', 'top-to-bottom then left-to-right']\n",
        "#@markdown (one of these orderings may be more stable for your video, as order is recalculated per frame)\n",
        "face_num = 0 #@param {type: 'integer'}\n",
        "#@markdown (use face_num = 0 to select the largest face, face_num >= 1 to select a face from all the faces ordered as above)\n",
        "min_conf = 0.9 #@param {type: 'number'}\n",
        "#@markdown (lower min_conf if faces are not detected, raise min_conf if there are false detections)\n",
        "temporal_smoothing = 0.9 #@param {type: 'number'}\n",
        "#@markdown (use temporal_smoothing = 0 to track head without smoothing, temporal_smoothing = 1 will not track head movement)\n",
        "top_extend_frac = 0.33 #@param {type: 'number'}\n",
        "bottom_extend_frac = 0.33 #@param {type: 'number'}\n",
        "aspect_ratio = 1.333 #@param {type: 'number'}\n",
        "start_seconds = 0 #@param {type: 'number'}\n",
        "duration_seconds = 0 #@param {type: 'number'}\n",
        "#@markdown (use duration_seconds = 0 for unrestricted duration)\n",
        "GFPGAN_model = '1.4' #@param ['1', '1.2', '1.3', '1.4', 'RestoreFormer']\n",
        "GFPGAN_factor = 0 #@param {type: 'integer'}\n",
        "#@markdown (use GFPGAN_factor = 0 to skip GFPGAN, GFPGAN_factor = 1 for restore without upscaling, GFPGAN_factor >= 2 for upscaling)\n",
        "max_width = 0 #@param {type: 'integer'}\n",
        "#@markdown (use max_width = 0 for unrestricted width)\n",
        "max_height = 0 #@param {type: 'integer'}\n",
        "#@markdown (use max_height = 0 for unrestricted height)\n",
        "temporal_mode = 'forward' #@param ['forward', 'reverse', 'forward + reverse']\n",
        "output_filename = 'output.mp4' #@param {type: 'string'}\n",
        "\n",
        "from time import time\n",
        "start_time = time()\n",
        "\n",
        "%cd /content\n",
        "\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "need_dl = True\n",
        "try:\n",
        "  if video_url == save_url and (video_url or i_just_uploaded_a_file_and_i_want_to_reuse_that_instead_of_uploading_a_new_one):\n",
        "    need_dl = False\n",
        "except:\n",
        "  pass\n",
        "if need_dl:\n",
        "  if not video_url:\n",
        "    %cd /content/sample_data\n",
        "    try:\n",
        "      uploaded = files.upload()\n",
        "    except Exception:\n",
        "      %cd /content\n",
        "      raise\n",
        "    for fn in uploaded:\n",
        "      orig_video = os.path.abspath(fn)\n",
        "      break\n",
        "    %cd /content\n",
        "  elif os.path.isfile(video_url):\n",
        "    orig_video = os.path.abspath(video_url)\n",
        "  elif os.path.isfile('/content/drive/MyDrive/' + video_url):\n",
        "    orig_video = '/content/drive/MyDrive/' + video_url\n",
        "  else:\n",
        "    orig_video = '/content/orig_video.mp4'\n",
        "    !rm -f $orig_video\n",
        "    !youtube-dl --no-playlist -f \"bestvideo[ext=mp4][vcodec!*=av01]+bestaudio[ext=m4a]/mp4[vcodec!*=av01]/bestvideo[ext=mp4]+bestaudio[ext=m4a]/bestvideo[ext=mp4]+bestaudio/mp4\" \"$video_url\" --merge-output-format mp4 -o $orig_video\n",
        "    if not os.path.exists(orig_video):\n",
        "      orig_video = '/content/orig_video.' + video_url.rsplit('.', 1)[1]\n",
        "      !wget \"$video_url\" -O $orig_video\n",
        "    assert os.path.exists(orig_video)\n",
        "  input_video = '/content/input_video' + os.path.splitext(orig_video)[-1]\n",
        "\n",
        "need_fix_duration = True\n",
        "try:\n",
        "  if not need_dl and start_seconds == save_start_seconds and duration_seconds == save_duration_seconds:\n",
        "    need_fix_duration = False\n",
        "except:\n",
        "  pass\n",
        "if need_fix_duration:\n",
        "  if start_seconds or duration_seconds:\n",
        "    !ffmpeg -y -ss $start_seconds -t $duration_seconds -i \"$orig_video\" -f mp4 $input_video\n",
        "  else:\n",
        "    !cp \"$orig_video\" $input_video\n",
        "\n",
        "save_url = video_url\n",
        "save_start_seconds = start_seconds\n",
        "save_duration_seconds = duration_seconds\n",
        "\n",
        "import imageio.v3 as iio\n",
        "from IPython.display import display, Image, Video, clear_output\n",
        "import face_alignment\n",
        "import cv2\n",
        "\n",
        "fa = face_alignment.FaceAlignment(landmarks_type=1)\n",
        "fps = iio.immeta(input_video)['fps']\n",
        "\n",
        "faces = []\n",
        "good_faces = []\n",
        "have_faces = False\n",
        "max_face_conf = 0\n",
        "max_face_conf_below = 0\n",
        "min_face_conf_above = 1\n",
        "for im in iio.imiter(input_video):\n",
        "  *_, bboxes = fa.get_landmarks_from_image(im, return_bboxes=True)\n",
        "  if bboxes is None:\n",
        "    bboxes = []\n",
        "  if len(bboxes):\n",
        "    max_face_conf = max(max_face_conf, *[b[-1] for b in bboxes])\n",
        "  if min_conf:\n",
        "    for b in bboxes:\n",
        "      if b[-1] < min_conf:\n",
        "        max_face_conf_below = max(max_face_conf_below, b[-1])\n",
        "    bboxes = [b for b in bboxes if b[-1] >= min_conf]\n",
        "  if len(bboxes):\n",
        "    min_face_conf_above = min(min_face_conf_above, *[b[-1] for b in bboxes])\n",
        "  bboxes = sorted(bboxes, key=lambda p: (p[0], p[2], p[1], p[3]) if face_order == 'left-to-right then top-to-bottom' else (p[1], p[3], p[0], p[2]))\n",
        "  if len(bboxes) > 1 and not have_faces:\n",
        "    have_faces = True\n",
        "    for i, (x0, y0, x1, y1, _) in enumerate(bboxes):\n",
        "        cv2.putText(im, str(i + 1), (min(int(x1), im.shape[1]) - 20, max(int(y1), 20)), 0, .7, (0, 255, 0), 2)\n",
        "    iio.imwrite('/content/numbers.png', im, compress_level=1)\n",
        "    clear_output()\n",
        "    display(Image('/content/numbers.png'))\n",
        "  if face_num:\n",
        "    bboxes = bboxes[face_num - 1 : face_num]\n",
        "  if bboxes:\n",
        "    bbox = sorted(bboxes, key=lambda p: (p[2]-p[0]) * (p[3]-p[1]))[-1]\n",
        "    faces.append(bbox[:-1])\n",
        "    good_faces.append(faces[-1])\n",
        "  else:\n",
        "    faces.append(None)\n",
        "\n",
        "print(f'{orig_video=} {max_face_conf=:.2f}')\n",
        "assert good_faces, f'No faces found. Consider decreasing min_conf below {max_face_conf:.2f}'\n",
        "median = sorted(good_faces, key=lambda p: (p[2]-p[0]) * (p[3]-p[1]))[len(good_faces) // 2]\n",
        "top = (median[3] - median[1]) * (.5 + top_extend_frac)\n",
        "h = top + (median[3] - median[1]) * (.5 + bottom_extend_frac)\n",
        "if h > im.shape[0]:\n",
        "  top = top / h * im.shape[0]\n",
        "  h = im.shape[0]\n",
        "w = min(round(h * aspect_ratio), im.shape[1])\n",
        "\n",
        "!rm -rf /content/in_frames\n",
        "!rm -rf /content/out_frames\n",
        "!mkdir -p /content/in_frames\n",
        "!mkdir -p /content/out_frames\n",
        "\n",
        "prev_face = good_faces[0]\n",
        "for i, (im, face) in enumerate(zip(iio.imiter(input_video), faces)):\n",
        "  x0, y0, x1, y1 = prev_face = prev_face if face is None else face\n",
        "\n",
        "  if i:\n",
        "    x = x*temporal_smoothing + (x0+x1)/2*(1-temporal_smoothing)\n",
        "    y = y*temporal_smoothing + (y0+y1)/2*(1-temporal_smoothing)\n",
        "  else:\n",
        "    x = (x0+x1) / 2\n",
        "    y = (y0+y1) / 2\n",
        "\n",
        "  x0 = max(x - w/2, 0)\n",
        "  x1 = int(min(x0 + w, im.shape[1]))\n",
        "  x0 = int(x1 - w)\n",
        "\n",
        "  y0 = max(y - top, 0)\n",
        "  y1 = int(min(y0 + h, im.shape[0]))\n",
        "  y0 = int(y1 - h)\n",
        "\n",
        "  im = im[y0:y1, x0:x1]\n",
        "  iio.imwrite(f'/content/in_frames/frame_{i:06d}.png', im, compress_level=1)\n",
        "\n",
        "reverse_filename = 'reverse_' + output_filename\n",
        "if GFPGAN_factor:\n",
        "  %cd /content/GFPGAN\n",
        "  !python inference_gfpgan.py -i /content/in_frames -o /content/out_frames -v $GFPGAN_model -s $GFPGAN_factor\n",
        "  %cd /content\n",
        "  im_folder = 'out_frames/restored_imgs'\n",
        "else:\n",
        "  im_folder = 'in_frames'\n",
        "\n",
        "if 'forward' in temporal_mode:\n",
        "  !ffmpeg -y -framerate $fps -thread_queue_size 0 -i /content/$im_folder/frame_%06d.png -i $input_video -c:v libx264 -c:a aac -map 0:v -map 1:a? -vf \"scale=min(iw\\,$max_width):min(ih\\,$max_height):force_original_aspect_ratio=decrease:force_divisible_by=2\" -pix_fmt yuv420p -profile:v baseline -movflags +faststart \"/content/$output_filename\"\n",
        "if 'reverse' in temporal_mode:\n",
        "  !ffmpeg -y -framerate $fps -thread_queue_size 0 -i /content/$im_folder/frame_%06d.png -i $input_video -c:v libx264 -c:a aac -map 0:v -map 1:a? -vf \"scale=min(iw\\,$max_width):min(ih\\,$max_height):force_original_aspect_ratio=decrease:force_divisible_by=2,reverse\" -af areverse -pix_fmt yuv420p -profile:v baseline -movflags +faststart \"/content/$reverse_filename\"\n",
        "\n",
        "if temporal_mode == 'reverse':\n",
        "  !mv \"/content/$reverse_filename\" \"/content/$output_filename\"\n",
        "elif temporal_mode == 'forward + reverse':\n",
        "  !echo file \"/content/$output_filename\" > list.txt\n",
        "  !echo file \"/content/$reverse_filename\" >> list.txt\n",
        "  concat_filename = 'concat_' + output_filename\n",
        "  !ffmpeg -y -f concat -safe 0 -i list.txt -c copy \"/content/$concat_filename\"\n",
        "  !mv \"/content/$concat_filename\" \"/content/$output_filename\"\n",
        "\n",
        "clear_output()\n",
        "if have_faces:\n",
        "  display(Image('/content/numbers.png'))\n",
        "meta = iio.immeta('/content/' + output_filename)\n",
        "print(f'took {(time()-start_time) / 60 :.1f} min. {orig_video=} output_video=/content/{output_filename} w={meta[\"size\"][0]} h={meta[\"size\"][1]} t={meta[\"duration\"]} fps={meta[\"fps\"]} {max_face_conf_below=:.2f} {min_face_conf_above=:.2f} {max_face_conf=:.2f}')\n",
        "print('if video does not show below, you can still download it!')\n",
        "display(Video('/content/' + output_filename, embed=True, html_attributes=\"autoplay controls loop\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lH4oJcBOKZcf",
        "cellView": "form"
      },
      "source": [
        "#@title Download\n",
        "\n",
        "from google.colab import files\n",
        "files.download('/content/' + output_filename)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}